---
title: "Tech Neutrality"
desc: "Just how morally neutral is technology?"
sortable: 2
---

Search the internet for "technology morally neutral", and you get a vast sea of ideas regarding the topic. Many claim that technology is indeed morally neutral, and that every piece of technology can be used for good and for evil alike.

## Hammers

One simple example of a neutral tech is the hammer. Sure, the hammer could empower you to hit someone over the head, but it also empowers you to build a house. It's hard to say which action a hammer empowers more, though considering warhammers or rubber mallets may make the comparison easier. Even so, the simple hammer is more or less morally neutral. There are many examples of such neutral tools, but some technologies, perhaps even most, have a moral bent, either for destruction or construction.

## Guns

Consider the gun. A popular quote, quipped often by the NRA and the like, is that:

>Guns don't kill people. People kill people.

This makes total sense, and the same can be said for knives, bazookas, and nuclear warheads. But consider the possible uses of a gun:

 * killing people
 * hunting
 * target practice (for killing people or for hunting)

The point of guns is to empower people to destroy things at a distance. Even when used for self defense, the gun is only able to deter an attacker because everyone involved is aware of its destructive capabilities. To be clear, guns, even when used to shoot people, have been used to accomplish very morally good things such as freeing the oppressed. However, they suffer a severe tendency towards destruction. Does this make guns evil? For the sake of this discussion, I'll say yes.

## Toothbrushes

Again, consider the toothbrush. Such an instrument grants its wielder the powers to:

 * brush teeth
 * clean other stuff
 * clean your gun that you use to shoot people

The point of toothbrushes is to empower people to clean stuff, mostly teeth (hence the name). An edge usage case is to clean non-teeth, and the evil use of the toothbrush is to clean things that will be used for evil purposes. Point is, that's a bit of a stretch. I'd consider cleaning in general to be morally good, and though the object of the cleaning may be used for evil, that doesn't mar the fact that cleaning is a good thing. Does this make the toothbrush morally good? I think so.

## How this all applies to tech

Every specific instance of technology falls (albeit loosely) into one of three categories:

 * Hammer-like, having neither a constructive nor a destructive bias, are morally neutral
 * Gun-like, having a destructive bias, are morally evil
 * Toothbrush-like, having a constructive bias, are morally good

In the tech industry, hammers, guns, and toothbrushes are all present in software. Corporate and governmental sponsors unfortunately seem to only be interested in developing guns, which currently take the form of big data collection and processing technologies. Given the money being thrown at them, we can expect their accuracy and caliber to dramatically increase in the coming years.

Toothbrushes in tech tend to be open source, simply because governments and corporations aren't interested in developing them in secret. A good example is cryptography, which serves the purpose of keeping data private - generally a good thing. Of course, like a toothbrush used to clean a gun, cryptography can be abused to facilitate evils like DRM. Even so, computer users with access to cryptography are empowered to encrypt their data, thus defending against data harvesting.

## What should we do about it?

What we shouldn't do is make the guns of the tech industry illegal. That move would be antithetical to everything that free software stands for. In fact, in order to be true to the freedoms that we advocate, _we_ shouldn't do anything.

But what should _I_ do? I should use my software development skills to invent toothbrushes instead of guns. I should develop strategies and tools for defending against the weapons that are being rolled out, and I should strive to warn other about the danger embedded in seemingly innocuous data harvesting schemes.
